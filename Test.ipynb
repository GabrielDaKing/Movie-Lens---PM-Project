{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Get test data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "LE = LabelEncoder()\n",
    "\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader as DL\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of review data\n",
    "cols = [\"user id\",\"item id\",\"rating\",\"timestamp\"]\n",
    "#encoding using ISO-8859-1 is used because utf-8 does not support all the characters in movie names\n",
    "df_data = pd.read_csv(\"ml-100k/u.data\",sep=\"\\t\",names=cols,header=None,encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of moviedata\n",
    "cols = [\"movie id\",\"movie title\",\"release date\",\"video release date\",\"IMDb URL\",\"unknown\",\n",
    "        \"Action\",\"Adventure\",\"Animation\",\"Children's\",\"Comedy\",\"Crime\",\"Documentary\",\n",
    "        \"Drama\",\"Fantasy\",\"Film-Noir\",\"Horror\",\"Musical\",\"Mystery\",\"Romance\",\"Sci-Fi\",\n",
    "        \"Thriller\",\"War\",\"Western\"]\n",
    "\n",
    "df_movie = pd.read_csv(\"ml-100k/u.item\",sep=\"|\",names=cols,header=None,encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of user data\n",
    "cols = [\"user id\",\"age\",\"gender\",\"occupation\",\"zip code\"]\n",
    "df_user = pd.read_csv(\"ml-100k/u.user\",sep=\"|\",names=cols,header=None,encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.0, 20.0]     109\n",
       "(23.0, 26.0]    105\n",
       "(35.0, 40.0]    100\n",
       "(31.0, 35.0]     98\n",
       "(29.0, 31.0]     96\n",
       "(40.0, 46.0]     94\n",
       "(46.0, 51.0]     93\n",
       "(20.0, 23.0]     92\n",
       "(51.0, 73.0]     85\n",
       "(26.0, 29.0]     71\n",
       "Name: age_group, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequency binning the ages into age groups as it will be easier for future analysis\n",
    "df_user['age_group'] = pd.qcut(df_user['age'],q=10,precision=0)\n",
    "\n",
    "#the bins are of unequal size due to repeating values in a bin\n",
    "df_user['age_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorize age_group, gender and occupation\n",
    "df_user['age_group'] = LE.fit_transform(df_user['age_group'])\n",
    "df_user['gender'] = LE.fit_transform(df_user['gender'])\n",
    "df_user['occupation'] = LE.fit_transform(df_user['occupation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=21, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc5): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc6): Linear(in_features=64, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create class for the neural network\n",
    "\n",
    "'''\n",
    "fully connected layer = fc\n",
    "nn.Linear(input, ouput)\n",
    "initial input =  number of columns = 21\n",
    "middle layers = 3 layers of 64 neurons\n",
    "final output = number of ratings (0-5) = 6\n",
    "'''\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(21, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 64)\n",
    "        self.fc5 = nn.Linear(64, 64)\n",
    "        self.fc6 = nn.Linear(64, 6)\n",
    "\n",
    "#ReLU activation function on hidden layers\n",
    "#Use log_softmax for output to get probability for classes\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "#view created network\n",
    "\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check with test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of review data\n",
    "cols = [\"user id\",\"item id\",\"rating\",\"timestamp\"]\n",
    "#encoding using ISO-8859-1 is used because utf-8 does not support all the characters in movie names\n",
    "u_train = pd.read_csv(\"ml-100k/u1.base\",sep=\"\\t\",names=cols,header=None,encoding=\"ISO-8859-1\")\n",
    "u_test = pd.read_csv(\"ml-100k/u1.test\",sep=\"\\t\",names=cols,header=None,encoding=\"ISO-8859-1\")\n",
    "\n",
    "##keep changing above files to u2.base, u2.test, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join all three dataframes\n",
    "training = pd.merge(pd.merge(u_train,\n",
    "                  df_user[[\"user id\",\n",
    "                           \"age_group\",\n",
    "                           \"gender\",\n",
    "                           \"occupation\"]],\n",
    "                  on='user id',\n",
    "                  how='left'),\n",
    "              df_movie,\n",
    "              left_on = 'item id',\n",
    "              right_on = 'movie id',\n",
    "              how ='left')\n",
    "\n",
    "testing = pd.merge(pd.merge(u_test,\n",
    "                  df_user[[\"user id\",\n",
    "                           \"age_group\",\n",
    "                           \"gender\",\n",
    "                           \"occupation\"]],\n",
    "                  on='user id',\n",
    "                  how='left'),\n",
    "              df_movie,\n",
    "              left_on = 'item id',\n",
    "              right_on = 'movie id',\n",
    "              how ='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    6778\n",
       "3    5182\n",
       "5    4457\n",
       "2    2192\n",
       "1    1391\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop unneccessary features\n",
    "training.drop([\"movie id\",\n",
    "        \"movie title\",\n",
    "        \"release date\",\n",
    "        \"video release date\",\n",
    "        \"IMDb URL\",\n",
    "        \"unknown\",\n",
    "        \"user id\",\n",
    "        \"item id\",\n",
    "        \"timestamp\"],axis=1, inplace=True)\n",
    "\n",
    "testing.drop([\"movie id\",\n",
    "        \"movie title\",\n",
    "        \"release date\",\n",
    "        \"video release date\",\n",
    "        \"IMDb URL\",\n",
    "        \"unknown\",\n",
    "        \"user id\",\n",
    "        \"item id\",\n",
    "        \"timestamp\"],axis=1, inplace=True)\n",
    "\n",
    "testing.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    5000\n",
       "4    5000\n",
       "3    5000\n",
       "2    5000\n",
       "1    4719\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#balance the training ratings using downsampling\n",
    "ns = 5000\n",
    "training_1 = training[training.rating == 1]\n",
    "training_2 = training[training.rating == 2]\n",
    "training_3 = training[training.rating == 3]\n",
    "training_4 = training[training.rating == 4]\n",
    "training_5 = training[training.rating == 5]\n",
    "\n",
    "#downsample all classes except 1 to 4719\n",
    "training_2_downsampled = resample(training_2,\n",
    "                                 replace = False,\n",
    "                                 n_samples = ns)\n",
    "training_3_downsampled = resample(training_3,\n",
    "                                 replace = False,\n",
    "                                 n_samples = ns)\n",
    "training_4_downsampled = resample(training_4,\n",
    "                                 replace = False,\n",
    "                                 n_samples = ns)\n",
    "training_5_downsampled = resample(training_5,\n",
    "                                 replace = False,\n",
    "                                 n_samples = ns)\n",
    "\n",
    "training = pd.concat([training_1, training_2_downsampled,\n",
    "                     training_3_downsampled,\n",
    "                     training_4_downsampled,\n",
    "                     training_5_downsampled])\n",
    "\n",
    "training.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1391\n",
       "3    1000\n",
       "2    1000\n",
       "5    1000\n",
       "4    1000\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#balance the testing ratings using downsampling\n",
    "ns = 1000\n",
    "testing_1 = testing[testing.rating == 1]\n",
    "testing_2 = testing[testing.rating == 2]\n",
    "testing_3 = testing[testing.rating == 3]\n",
    "testing_4 = testing[testing.rating == 4]\n",
    "testing_5 = testing[testing.rating == 5]\n",
    "\n",
    "#downsample all classes except 1 to 1391\n",
    "testing_2_downsampled = resample(testing_2,\n",
    "                                 replace = False,\n",
    "                                 n_samples = ns)\n",
    "testing_3_downsampled = resample(testing_3,\n",
    "                                 replace = False,\n",
    "                                 n_samples = ns)\n",
    "testing_4_downsampled = resample(testing_4,\n",
    "                                 replace = False,\n",
    "                                 n_samples = ns)\n",
    "testing_5_downsampled = resample(testing_5,\n",
    "                                 replace = False,\n",
    "                                 n_samples = ns)\n",
    "\n",
    "testing = pd.concat([testing_1, testing_2_downsampled,\n",
    "                     testing_3_downsampled,\n",
    "                     testing_4_downsampled,\n",
    "                     testing_5_downsampled])\n",
    "\n",
    "testing.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resetting the index\n",
    "training.reset_index(inplace = True, drop = True)\n",
    "testing.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorize age_group, gender and occupation\n",
    "training['age_group'] = LE.fit_transform(training['age_group'])\n",
    "training['gender'] = LE.fit_transform(training['gender'])\n",
    "training['occupation'] = LE.fit_transform(training['occupation'])\n",
    "\n",
    "testing['age_group'] = LE.fit_transform(testing['age_group'])\n",
    "testing['gender'] = LE.fit_transform(testing['gender'])\n",
    "testing['occupation'] = LE.fit_transform(testing['occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for PyTorch\n",
    "rank_train = training['rating'].values\n",
    "training_input = training.drop([\"rating\"], axis=1)\n",
    "train = []\n",
    "\n",
    "for index,row in training_input.iterrows():\n",
    "    t = (torch.tensor(row.values), rank_train[index])\n",
    "    train.append(t)\n",
    "train = tuple(train)\n",
    "\n",
    "rank_test = testing['rating'].values\n",
    "testing_input = testing.drop([\"rating\"], axis=1)\n",
    "\n",
    "test = []\n",
    "\n",
    "for index,row in testing_input.iterrows():\n",
    "    t = (torch.tensor(row.values), rank_test[index])\n",
    "    test.append(t)\n",
    "test = tuple(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide into batches\n",
    "'''\n",
    "batch_size = how many inputs to pass to model at a time\n",
    "shuffle = to shuffle inputs or not\n",
    "'''\n",
    "trainset = DL(train, batch_size=32, shuffle=True)\n",
    "testset = DL(test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6264, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5517, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5462, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5498, grad_fn=<NllLossBackward>)\n",
      "tensor(1.5764, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#lr = learning rate = 0.001\n",
    "opt = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "#EPOCHS = number of times to iterate over dataset\n",
    "EPOCHS = 5\n",
    "\n",
    "#train the network\n",
    "'''\n",
    "loss = error\n",
    "zero_grad() = makes gradient zero after batch\n",
    "nll_loss = calculates loss to update weights\n",
    "if data is 1 hot vector, use mean squared error\n",
    "backward() = propogate the weights backward\n",
    "opt.step() = adjusts the weights\n",
    "'''\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 21).float())\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        opt.step() \n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.26470042663698756\n"
     ]
    }
   ],
   "source": [
    "#check the model\n",
    "'''\n",
    "no_grad() = as test data will not be used for optimization,\n",
    "we do not need to calculate gradient for it\n",
    "'''\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 21).float())\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \",correct/total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
