{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Get test data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1557,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader as DL\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1558,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of moviedata\n",
    "cols = [\"movie id\",\"movie title\",\"release date\",\"video release date\",\"IMDb URL\",\"unknown\",\n",
    "        \"Action\",\"Adventure\",\"Animation\",\"Childrens\",\"Comedy\",\"Crime\",\"Documentary\",\n",
    "        \"Drama\",\"Fantasy\",\"Film-Noir\",\"Horror\",\"Musical\",\"Mystery\",\"Romance\",\"Sci-Fi\",\n",
    "        \"Thriller\",\"War\",\"Western\"]\n",
    "\n",
    "df_movie = pd.read_csv(\"ml-100k/u.item\",sep=\"|\",names=cols,header=None,encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1559,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of user data\n",
    "cols = [\"user id\",\"age\",\"gender\",\"occupation\",\"zip code\"]\n",
    "df_user = pd.read_csv(\"ml-100k/u.user\",sep=\"|\",names=cols,header=None,encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1560,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency binning the ages into age groups as it will be easier for future analysis\n",
    "df_user['age_group'] = pd.qcut(df_user['age'],q=10,precision=0)\n",
    "\n",
    "#the bins are of unequal size due to repeating values in a bin\n",
    "#df_user['age_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check with test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1561,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of review data\n",
    "cols = [\"user id\",\"item id\",\"rating\",\"timestamp\"]\n",
    "#encoding using ISO-8859-1 is used because utf-8 does not support all the characters in movie names\n",
    "u_train = pd.read_csv(\"ml-100k/u5.base\",sep=\"\\t\",names=cols,header=None,encoding=\"ISO-8859-1\")\n",
    "u_test = pd.read_csv(\"ml-100k/u5.test\",sep=\"\\t\",names=cols,header=None,encoding=\"ISO-8859-1\")\n",
    "\n",
    "##keep changing above files to u2.base, u2.test, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1562,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join all three dataframes\n",
    "training = pd.merge(pd.merge(u_train,\n",
    "                  df_user[[\"user id\",\n",
    "                           \"age_group\",\n",
    "                           \"gender\",\n",
    "                           \"occupation\"]],\n",
    "                  on='user id',\n",
    "                  how='left'),\n",
    "              df_movie,\n",
    "              left_on = 'item id',\n",
    "              right_on = 'movie id',\n",
    "              how ='left')\n",
    "\n",
    "testing = pd.merge(pd.merge(u_test,\n",
    "                  df_user[[\"user id\",\n",
    "                           \"age_group\",\n",
    "                           \"gender\",\n",
    "                           \"occupation\"]],\n",
    "                  on='user id',\n",
    "                  how='left'),\n",
    "              df_movie,\n",
    "              left_on = 'item id',\n",
    "              right_on = 'movie id',\n",
    "              how ='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1563,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorize age_group, gender and occupation using 1-hot encoder\n",
    "training['age_group'] = pd.Categorical(training['age_group'])\n",
    "training['gender'] = pd.Categorical(training['gender'])\n",
    "training['occupation'] = pd.Categorical(training['occupation'])\n",
    "\n",
    "age_group_dummies = pd.get_dummies(training['age_group'])\n",
    "gender_dummies = pd.get_dummies(training['gender'])\n",
    "occupation_dummies = pd.get_dummies(training['occupation'])\n",
    "\n",
    "training = pd.concat([training,\n",
    "                age_group_dummies,\n",
    "                gender_dummies,\n",
    "                occupation_dummies], axis=1)\n",
    "\n",
    "training.drop(['age_group',\n",
    "        'gender',\n",
    "        'occupation'], axis=1, inplace=True)\n",
    "\n",
    "#verify categorization\n",
    "#training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1564,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorize age_group, gender and occupation using 1-hot encoder\n",
    "testing['age_group'] = pd.Categorical(testing['age_group'])\n",
    "testing['gender'] = pd.Categorical(testing['gender'])\n",
    "testing['occupation'] = pd.Categorical(testing['occupation'])\n",
    "\n",
    "age_group_dummies = pd.get_dummies(testing['age_group'])\n",
    "gender_dummies = pd.get_dummies(testing['gender'])\n",
    "occupation_dummies = pd.get_dummies(testing['occupation'])\n",
    "\n",
    "testing = pd.concat([testing,\n",
    "                age_group_dummies,\n",
    "                gender_dummies,\n",
    "                occupation_dummies], axis=1)\n",
    "\n",
    "testing.drop(['age_group',\n",
    "        'gender',\n",
    "        'occupation'], axis=1, inplace=True)\n",
    "\n",
    "#verify categorization\n",
    "#testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1565,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unneccessary features\n",
    "training.drop([\"movie id\",\n",
    "        \"movie title\",\n",
    "        \"release date\",\n",
    "        \"video release date\",\n",
    "        \"IMDb URL\",\n",
    "        \"unknown\",\n",
    "        \"user id\",\n",
    "        \"item id\",\n",
    "        \"timestamp\"],axis=1, inplace=True)\n",
    "\n",
    "testing.drop([\"movie id\",\n",
    "        \"movie title\",\n",
    "        \"release date\",\n",
    "        \"video release date\",\n",
    "        \"IMDb URL\",\n",
    "        \"unknown\",\n",
    "        \"user id\",\n",
    "        \"item id\",\n",
    "        \"timestamp\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1566,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(training.rating.value_counts())\n",
    "#print(testing.rating.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1567,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balance the training ratings using upsampling\n",
    "ns = 25000\n",
    "training_1 = training[training.rating == 1]\n",
    "training_2 = training[training.rating == 2]\n",
    "training_3 = training[training.rating == 3]\n",
    "training_4 = training[training.rating == 4]\n",
    "training_5 = training[training.rating == 5]\n",
    "\n",
    "training_1_upsampled = resample(training_1,\n",
    "                                 replace = True,\n",
    "                                 n_samples = ns,\n",
    "                                 random_state=123)\n",
    "training_2_upsampled = resample(training_2,\n",
    "                                 replace = True,\n",
    "                                 n_samples = ns,\n",
    "                                 random_state=123)\n",
    "training_3_upsampled = resample(training_3,\n",
    "                                 replace = True,\n",
    "                                 n_samples = ns,\n",
    "                                 random_state=123)\n",
    "training_4_upsampled = resample(training_4,\n",
    "                                 replace = True,\n",
    "                                 n_samples = ns,\n",
    "                                 random_state=123)\n",
    "training_5_upsampled = resample(training_5,\n",
    "                                 replace = True,\n",
    "                                 n_samples = ns,\n",
    "                                 random_state=123)\n",
    "\n",
    "training = pd.concat([training_1_upsampled,\n",
    "                training_2_upsampled,\n",
    "                training_3_upsampled,\n",
    "                training_4_upsampled,\n",
    "                training_5_upsampled])\n",
    "\n",
    "#training.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1568,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balance the testing ratings using upsampling\n",
    "ns = 6500\n",
    "testing_1 = testing[testing.rating == 1]\n",
    "testing_2 = testing[testing.rating == 2]\n",
    "testing_3 = testing[testing.rating == 3]\n",
    "testing_4 = testing[testing.rating == 4]\n",
    "testing_5 = testing[testing.rating == 5]\n",
    "\n",
    "testing_1_upsampled = resample(testing_1,\n",
    "                                 replace = True,\n",
    "                                 n_samples = ns,\n",
    "                                 random_state=123)\n",
    "testing_2_upsampled = resample(testing_2,\n",
    "                                 replace = True,\n",
    "                                 n_samples = ns,\n",
    "                                 random_state=123)\n",
    "testing_3_upsampled = resample(testing_3,\n",
    "                                 replace = True,\n",
    "                                 n_samples = ns,\n",
    "                                 random_state=123)\n",
    "testing_4_upsampled = resample(testing_4,\n",
    "                                 replace = True,\n",
    "                                 n_samples = ns,\n",
    "                                 random_state=123)\n",
    "testing_5_upsampled = resample(testing_5,\n",
    "                                 replace = True,\n",
    "                                 n_samples = ns,\n",
    "                                 random_state=123)\n",
    "\n",
    "testing = pd.concat([testing_1_upsampled,\n",
    "                testing_2_upsampled,\n",
    "                testing_3_upsampled,\n",
    "                testing_4_upsampled,\n",
    "                testing_5_upsampled])\n",
    "\n",
    "#testing.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1569,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resetting the index\n",
    "training.reset_index(inplace = True, drop = True)\n",
    "testing.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1570,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(training.shape)\n",
    "#print(testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1571,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for PyTorch\n",
    "\n",
    "n_input = training.shape[1] - 1\n",
    "\n",
    "rank_train = training['rating'].values\n",
    "training_input = training.drop([\"rating\"], axis=1)\n",
    "train = []\n",
    "\n",
    "for index,row in training_input.iterrows():\n",
    "    t = (torch.tensor(row.values), rank_train[index])\n",
    "    train.append(t)\n",
    "train = tuple(train)\n",
    "\n",
    "rank_test = testing['rating'].values\n",
    "testing_input = testing.drop([\"rating\"], axis=1)\n",
    "\n",
    "test = []\n",
    "\n",
    "for index,row in testing_input.iterrows():\n",
    "    t = (torch.tensor(row.values), rank_test[index])\n",
    "    test.append(t)\n",
    "test = tuple(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1572,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create class for the neural network\n",
    "\n",
    "'''\n",
    "fully connected layer = fc\n",
    "nn.Linear(input, ouput)\n",
    "initial input =  number of columns = 51\n",
    "middle layers = 3 layers of 64 neurons\n",
    "final output = number of ratings (0-5) = 6\n",
    "'''\n",
    "\n",
    "n_hidden_neurons = int((2*n_input/3)+6)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_input, n_hidden_neurons)\n",
    "        self.fc2 = nn.Linear(n_hidden_neurons, n_hidden_neurons)\n",
    "        self.fc3 = nn.Linear(n_hidden_neurons, n_hidden_neurons)\n",
    "        self.fc4 = nn.Linear(n_hidden_neurons, 6)\n",
    "\n",
    "#ReLU activation function on hidden layers\n",
    "#Use log_softmax for output to get probability for classes\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "#view created network\n",
    "\n",
    "net = Net()\n",
    "#net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1573,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide into batches\n",
    "'''\n",
    "batch_size = how many inputs to pass to model at a time\n",
    "shuffle = to shuffle inputs or not\n",
    "'''\n",
    "trainset = DL(train, batch_size=64, shuffle=True)\n",
    "testset = DL(test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5542, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4800, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4322, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6306, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4752, grad_fn=<NllLossBackward>)\n",
      "tensor(1.4655, grad_fn=<NllLossBackward>)\n",
      "tensor(1.6238, grad_fn=<NllLossBackward>)\n",
      "tensor(1.3882, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2404, grad_fn=<NllLossBackward>)\n",
      "tensor(1.2477, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#lr = learning rate = 0.001\n",
    "opt = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "#EPOCHS = number of times to iterate over dataset\n",
    "EPOCHS = 10\n",
    "\n",
    "#train the network\n",
    "'''\n",
    "loss = error\n",
    "zero_grad() = makes gradient zero after batch\n",
    "nll_loss = calculates loss to update weights\n",
    "if data is 1 hot vector, use mean squared error\n",
    "backward() = propogate the weights backward\n",
    "opt.step() = adjusts the weights\n",
    "'''\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, n_input).float())\n",
    "        loss = F.nll_loss(output, y)\n",
    "        loss.backward()\n",
    "        opt.step() \n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1575,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.2849\n"
     ]
    }
   ],
   "source": [
    "#check the model\n",
    "'''\n",
    "no_grad() = as test data will not be used for optimization,\n",
    "we do not need to calculate gradient for it\n",
    "'''\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, n_input).float())\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \",round(correct/total, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
